---
title: "Final_Report"
output: pdf_document
date: "2025-12-03"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{=html}
<!-- 
R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
 -->
```

```{r imports, include=FALSE}
# Load required packages
if(!require(pwr)) install.packages("pwr", dependencies=TRUE)
if(!require(ggplot2)) install.packages("ggplot2", dependencies=TRUE)
install.packages("readxl")
library(pwr)
library(ggplot2)
library(sandwich)
library(stargazer)
library(AER)
```

```{r DataIngest, include=FALSE}
library(readxl)
library(data.table)
library(AER)
excel_sheets("Experiment_Data.xlsx")

df <- as.data.table(read_excel("Experiment_Data.xlsx", sheet = "Final Data"))
df
```

```{r DataCleanup, include=FALSE}
df[, unique(`Breed Group`)]
df[, unique(`Treatment Group`)]
df[, unique(Outcome)]

experiment_data <- df[, .(
  DogName        = `Name - AdoptAPet`,
  Stigma         = ifelse(`Breed Group` == "Stigma", 1L, 0L),
  Treatment      = `Treatment Group`,
  Outcome_Experiment = ifelse(Outcome == "None", 0L, 1L),
  Compliance = fifelse(
    (`Treatment Group` == 1 & (is.na(Bio) | Bio %in% c("NA", "N/A"))) |
    (`Treatment Group` == 1 & Outcome %in% c("Transported - pre bio", "Adopted - pre bio")),
    0L,  
    1L   
  ),
  Pretreat_LOS = `PreTreat LOS`,
  Pretreat_views = `PreTreat- Seen_SearchResults_2008`,
  Pretreat_open = `PreTreat- Details_Opened_2008`,
  Color = Color,
  Black_Dog = c(0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,0,0,0,1),
  Age = Age,
  Sex = ifelse(Sex=="male",1,0),
  Size = ifelse(Size %in% c("Med. 26-60 lbs (12-27 kg)"),"medium",ifelse(Size %in% c("Large 61-100 lbs (28-45 kg)"),"large","small")),
  Housebroken = ifelse(Housebroken=="Yes",1,0),
  Special_Needs = ifelse(Special_Needs=="Yes",1,0),
  Kids = ifelse(OK_With_Kids=="Yes", 1,0),
  Dogs = ifelse(OK_With_Dogs=="Yes",1,0)
)]

experiment_data
```

```{=html}
<!-- 
Note: Dogs, Kids, Special Needs, Housebroken are all pretty much the same for each dog so can ignore
Color: primary color black - 1/0
 -->
```

# Introduction

Introduction goes here... 1) An introduction that poses the research
question. 2) Do not include a signposting paragraph. These are tedious
and your paper should be well structured enough that it stands without
one. 3) A justification -- based on either previous research (theory),
business intuition (inductive theory), or some other structure (lazy
theory) -- that informs your reader why you have chosen to conduct this
specific experiment. 4) A specific statement of the hypotheses that are
up for test and why you think they should show a difference (this comes
from #3 above).

# Dog Adoption Field Experiment

## Potential Outcomes

Comparison of Potential Outcomes - A clear statement is made that
describes what potential outcomes are going to be compared to which
other. This could come in the form of an explicit appeal to the ROXO
comparison, but it need not necessarily be. Clarity in this exposition
is crucial.

## Randomization Process

Randomization Process - Given the design that you've written down, how
will you actually go about creating random assignment into one or more
of the groups? If this is not explicitly random, then detail what trade
offs you are having to make. If you have any reason to doubt that
randomization was not conducted according to plan -- that is, it isn't
random -- then checks to evaluate any deviations should be presented,
consequences for these deviations considered, and remedies -- to the
extent they are possible -- proposed.

## Treatment

Treatment - What is the treatment? Specifics of the feature, or
experience, or intervention should be provided somewhere in the
document; frequently this works well in the main body; it can also work
well in an appendix. If there was not perfect compliance to the
treatment regime, then checks to evaluate deviations should be presented
and deviations considered. To the extent that they are possible,
remedies should be proposed.

## Experiment Population

Your report should make very clear who was considered for involvement in
your experiment, who was assigned, and whose data will eventually be
used. Consider, as an example, the flow chart on p. 439 of Gerber and
Green. (Note that the U.S. Food and Drug Administration calls this
information a CONSORT statement.

\*\* I'd say this is where we can talk about how we go from a shelter of
100+ dogs, down to \~60 dogs in our experiment... with the reason being:
1) A dog is not eligible for adoption until a surgery date is scheduled.
2) There are many types of dog intakes, including stray, which require
at least a 10 day hold. 3) Since our treatment was to add a bio, we had
to ignore any dogs with existing bios (ended up being \~30 dogs I think)

## Power Calculation

Power Calculation -- Given pre-experiment assumptions about effect size
and experiment size, how much power does the experiment anticipate
generating.

```{r PowerCalculation, echo=FALSE}
# Function to calculate power for binary outcome
binary_power <- function(p1, p2, n, sig.level = 0.05) {
    h <- 2 * asin(sqrt(p1)) - 2 * asin(sqrt(p2))
    power_result <- pwr.2p.test(h = abs(h), n = n, sig.level = sig.level, alternative = "two.sided")
    return(power_result$power)
}

# Function to find required sample size for a target power
sample_for_power <- function(power_target, p1, p2, sig.level = 0.05) {
    h <- 2 * asin(sqrt(p1)) - 2 * asin(sqrt(p2))
    n_needed <- pwr.2p.test(h = abs(h), sig.level = sig.level, power = power_target, alternative = "two.sided")$n
    return(ceiling(n_needed))  # round up to nearest integer
}

# Parameters
p1 <- 0.5  # control group proportion
p2 <- 0.6  # treatment group proportion
target_powers <- c(0.80, 0.85, 0.90, 0.92, 0.95)

# Compute sample sizes
sample_sizes <- sapply(target_powers, sample_for_power, p1 = p1, p2 = p2)

# Compute actual power for these sample sizes
powers_computed <- sapply(sample_sizes, binary_power, p1 = p1, p2 = p2)

# Create a table
power_table <- data.frame(
    Target_Power = target_powers,
    Sample_Size_Per_Group = sample_sizes,
    Actual_Power = round(powers_computed, 3),
    Total_Size = sample_sizes * 2
)

# Print table
print(power_table)


# Plot power vs sample size

# Define a range of sample sizes
sample_range <- seq(300, 700, by = 10)

# Compute power for each sample size
power_values <- sapply(sample_range, binary_power, p1 = p1, p2 = p2)

# Create a data frame for plotting
power_df <- data.frame(
    Sample_Size = sample_range,
    Power = power_values
)

# Plot power vs sample size
ggplot(power_df, aes(x = Sample_Size, y = Power)) +
    geom_line(color = "blue", size = 1.2) +
    geom_hline(yintercept = c(0.8, 0.85, 0.9, 0.95), linetype = "dashed", color = "red") +
    labs(
        title = "Power vs Sample Size for Binary Outcome Experiment",
        x = "Sample Size per Group",
        y = "Power"
    ) +
    theme_minimal(base_size = 14)
```

# Analysis

## Data

Data: the data is clearly detailed, and the reader can understand at a
conceptual and operational level - The outcome that is being measured
and reasoned about - How the treatment that was described in the
/Experimental Details/ section maps into the operational space for the
models. - Important covariate features that will be used in the
analysis.

## Models

Models: there is a clear, structured, and progressive plan for testing
and reporting. - Data - Models use data from units that is appropriate
for estimating the causal quantity of interest. - Design - Estimates for
causal effects identify the same quantities that are designed for in the
/Experiment Details/ section. - Models - Models first estimate simple
"treatment-control" contrast, unadorned with additional model features
intended to improve precision; - Models - To the extent that it was
designed for, models increase precision of estimates using 'good
controls' - If implicated in the Theory or Hypotheses, either HTE or
subgroup analysis are handled appropriately.

\*\*Spoke with Clinton about this...He suggested running/displaying 3
models (ITT or IVreg... he said that we are good with using lm and not
needing a log model, the lm coefficient will tell us the adaptability
rate): 1) Simple model: Outcome \~ Treatment 2) Control Variables:
Outcome \~ Treatment + Stigma + Complier 3) All Features: Outcome \~
Treatment + Stigma + Complier + Pretreat_LOS + Pretreat_views +
Pretreat_open + Age + Sex + Size + (include F-tests to see if the
additional features add any value)

```{r}
head(experiment_data)
```

**ITT Models:**

```{r}
# starting with ITT (intent to treat)
model_ITT_1 = lm(Outcome_Experiment ~ Treatment, data = experiment_data)

summary(model_ITT_1)
```

```{r}
# starting with ITT (intent to treat)
# won't compliance add contamination from outcomes? since that's a post-assignment variable..
# excluded compliance for now.
model_ITT_2 = lm(Outcome_Experiment ~ Treatment + Stigma, data = experiment_data)

summary(model_ITT_2)
```

```{r}
# excluded compliance for now since it's a post-treatment variable
model_ITT_3 = lm(Outcome_Experiment ~ Treatment + Stigma + Pretreat_LOS + Pretreat_views +
                   Pretreat_open + Age + Sex + Size + Black_Dog, data = experiment_data)

summary(model_ITT_3)
```

```{r}
# made a fourth, slightly simpler model because I don't like including views/clickthrough rates. Feels too specific and not that helpful from a practical, prediction perspective. Also VIEWS in particular is very changeable depending on how long the dog's profile was up

model_ITT_4 = lm(Outcome_Experiment ~ Treatment + Stigma + Age + Sex + Size + Black_Dog, data = experiment_data)

summary(model_ITT_4)
```

**Instrumental Variable Models:**

```{r}
# IV regression data prep
treatmentgrp_and_treated = (experiment_data$Treatment == 1 & experiment_data$Compliance == 1)

controlgrp_and_treated = (experiment_data$Treatment == 0 & experiment_data$Compliance == 0)


experiment_data$actually_treated = (treatmentgrp_and_treated | controlgrp_and_treated)

head(experiment_data)
```

```{r}
# check how many non-compliers overall. Only six because we filtered out dogs assigned to control who ended up with bios. Should we have done that if we planned to proceed with IV regression? Maybe should add them back in for IV regression
table(experiment_data$Compliance)
```

IV Regression Models:

```{r}
model_IV_1 = ivreg(Outcome_Experiment  ~ actually_treated | Treatment, data = experiment_data)

summary(model_IV_1)
```

```{r}
model_IV_2 = ivreg(Outcome_Experiment  ~ actually_treated + Stigma | Treatment + Stigma, data = experiment_data)

summary(model_IV_2)
```

```{r}

model_IV_3 = ivreg(Outcome_Experiment  ~ actually_treated + Stigma + Pretreat_LOS + Pretreat_views +
                   Pretreat_open + Age + Sex + Size + Black_Dog | Treatment + Stigma + Pretreat_LOS + Pretreat_views +
                   Pretreat_open + Age + Sex + Size + Black_Dog, data = experiment_data)

summary(model_IV_3)
```

```{r}
# made a fourth, slightly simpler model because I don't like including views/clickthrough rates. Feels too specific and not that helpful from a practical, prediction perspective. Also VIEWS in particular is very changeable depending on how long the dog's profile was up
model_IV_4 = ivreg(Outcome_Experiment  ~ actually_treated + Stigma + Age + Sex + Size + Black_Dog | Treatment + Stigma + Age + Sex + Size + Black_Dog, data = experiment_data)

summary(model_IV_4)
```

To do in model section:

(1) Decide if we are doing IV reg or ITT

(2) F-tests

```{r}
experiment_data
```


```{r SimpleModel}
m1 <- experiment_data[ , lm(Outcome_Experiment~Treatment)]
m2 <- experiment_data[ , lm(Outcome_Experiment~Treatment+Stigma)]
m1$vcovHC_ <- vcovHC(m1)
m2$vcovHC_ <- vcovHC(m2)
stargazer(m1, m2,
          type = "text",
          se = list(sqrt(diag(m1$vcovHC_)),sqrt(diag(m2$vcovHC_))),  
          title = "Treatment Effects With and Without Block Average Controls",
          column.labels = c("Without Block", "With Block"),
          covariate.labels = c("Treatment", "Block Average"),
          dep.var.labels = "Adoption Rate",
          model.numbers = FALSE,
          notes = "Robust standard errors in parentheses")
```
The simple model tells us that having a bio leads to a ~13% greater probability of being adopted. When controling for stigma breeds, by being a stigma breed there is a ~18% reduction in adoption rate, however when being a stigma breed and having a bio that improves to only a ~6.5% reduction in adoption rate. However, the standard errors are very large which leads these coefficients to bot being stat sig.  
```{r}
first_stage <- lm(Treatment ~ Compliance + Stigma, data = experiment_data)
summary(first_stage)
```


```{r}
m3 <- experiment_data[ , ivreg(
  Outcome_Experiment ~ Compliance + Stigma | Treatment + Stigma
)]
m4 <- experiment_data[ , ivreg(
  Outcome_Experiment ~ Compliance + Stigma + Pretreat_LOS + Pretreat_views + Pretreat_open + Age + Sex + Size + Black_Dog | Treatment + Stigma + Pretreat_LOS + Pretreat_views + Pretreat_open + Age + Sex + Size + Black_Dog
)]
m3$vcovHC_ <- vcovHC(m3)
m4$vcovHC_ <- vcovHC(m4)
stargazer(m3, m4,
          type = "text",
          se = list(sqrt(diag(m3$vcovHC_)),sqrt(diag(m4$vcovHC_))),  
          title = "Treatment Effects of Compliars",
          column.labels = c("Small Model with Compliance (CATE)","Large Model with Compliance (CATE)"),
          dep.var.labels = "Adoption Rate",
          model.numbers = FALSE,
          notes = "Robust standard errors in parentheses")
```

```{r}
m5 <- experiment_data[Compliance==1, lm(Outcome_Experiment ~ Treatment)]
m6 <- experiment_data[Compliance==1, lm(Outcome_Experiment ~ Treatment + Stigma)]
m7 <- experiment_data[Compliance==1, lm(Outcome_Experiment ~ Treatment + Stigma +
                                         Pretreat_LOS + Pretreat_views + Pretreat_open +
                                         Age + Sex + Size + Black_Dog)]

# Use HC2 instead of HC3
vcov5 <- vcovHC(m5, type = "HC1")
vcov6 <- vcovHC(m6, type = "HC1")
vcov7 <- vcovHC(m7, type = "HC1")

stargazer(
  m5, m6, m7,
  type = "text",
  se = list(
    sqrt(diag(vcov5)),
    sqrt(diag(vcov6)),
    sqrt(diag(vcov7))
  ),
  title = "Treatment Effects With and Without Block Average Controls",
  column.labels = c("Simple Model", "Blocked Model", "Full Model"),
  dep.var.labels = "Adoption Rate",
  model.numbers = FALSE,
  notes = "HC2 robust standard errors in parentheses"
)
```

```{r}
# 1) Subset data first
d <- experiment_data[Compliance == 1, ]

# 2) Fit models
m5 <- lm(Outcome_Experiment ~ Treatment, data = d)
m6 <- lm(Outcome_Experiment ~ Treatment + Stigma, data = d)
m7 <- lm(
  Outcome_Experiment ~ Treatment + Stigma +
    Pretreat_LOS + Pretreat_views + Pretreat_open +
    Age + Sex + Size + Black_Dog,
  data = d
)

# 3) Helper to get robust SE vector that is aligned to the coef() order
robust_se <- function(model, type = "HC1") {
  V <- vcovHC(model, type = type)
  se <- sqrt(diag(V))
  # ensure order matches coef()
  se[match(names(coef(model)), names(se))]
}

se_m5 <- robust_se(m5, type = "HC1")
se_m6 <- robust_se(m6, type = "HC1")
se_m7 <- robust_se(m7, type = "HC1")

# (optional) sanity checks
length(coef(m5)); length(se_m5)
length(coef(m6)); length(se_m6)
length(coef(m7)); length(se_m7)

# 4) Stargazer with aligned SEs
stargazer(
  m5, m6, m7,
  type = "text",
  se = list(se_m5, se_m6, se_m7),
  title = "Treatment Effects With and Without Block Average Controls",
  column.labels = c("Simple Model", "Blocked Model", "Full Model"),
  dep.var.labels = "Adoption Rate",
  model.numbers = FALSE,
  notes = "Robust standard errors (HC2) in parentheses"
)
```


## Results

Tables: The findings of the experiment can be read through a limited
number of tables. Tables: - Communicate a specific point - Are titled,
have axes labeled, and legends included. - Include a caption that is
informative enough that the figure is readable without reading more than
the Abstract of the paper and knowing the treatments and outcome
measures.

Supporting Figures: - Communicate a specific point - Are titled, have
axes labeled, and legends included. - Include a caption that is
informative enough that the figure is readable without reading more than
the Abstract of the paper and knowing the treatments and outcome
measures.

\*\*Clinton suggested: - SJ plot - Box plot - Scatter plot with mean
adoption rate for treatment/control

## Lessons Learned and Further Research Suggestions
